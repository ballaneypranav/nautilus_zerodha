TITLE: Retrieve DBN Time Series Data and Convert to Pandas DataFrame (Python)
DESCRIPTION: Illustrates how to fetch time series data in DBN format using `client.timeseries.get_range` with specified dataset, symbols, schema, and time constraints. The retrieved `dbn_data` object can then be easily converted into a pandas DataFrame for further analysis and manipulation.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,data format,data handling,data:loading,integration:Databento,library:pandas
CODE:
```
dbn_data = client.timeseries.get_range(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],
    schema="ohlcv-1h",
    start="2022-06-06",
    limit=3
)

dbn_data.to_df()
```
----------------------------------------
TITLE: Download and Export Market Data to DBNStore
DESCRIPTION: This snippet downloads the specified market data using `client.timeseries.get_range` and then exports it to a compressed DBNStore file (`.dbn.zst`). This format is efficient for storage and significantly smaller than CSV, making it suitable for large datasets.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,ZST,data format,data handling,data:loading,data:persistence,integration:Databento
CODE:
```
data = client.timeseries.get_range(
    dataset=dataset,
    symbols=[symbol],
    stype_in=stype_in,
    schema=schema,
    start=start,
    end=end,
)

# Export data in DBNStore format (CSV data are 10x bigger)
data.to_file(f"{dataset}_{symbol}_{start}-{end}.{schema}.dbn.zst")
```
----------------------------------------
TITLE: Resolve Financial Symbols to Instrument IDs (Python)
DESCRIPTION: Demonstrates how to use the `client.symbology.resolve` method to convert input symbology types, such as raw symbols, into output symbology types like `instrument_id`. This method supports filtering by dataset, symbols, input/output types, and date ranges, returning a dictionary containing the resolved IDs and metadata.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,instrument ID,integration,resolve,symbology
CODE:
```
result = client.symbology.resolve(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],
    stype_in="raw_symbol",
    stype_out="instrument_id",
    start_date="2022-06-01",
    end_date="2022-06-30",
)

result
```
----------------------------------------
TITLE: Convert DBN Data to Pandas DataFrame (Python)
DESCRIPTION: Shows how to transform a DBN data object into a pandas DataFrame using the `dbn_data.to_df()` method. This conversion enables leveraging pandas' powerful data manipulation and analysis capabilities.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,data format,data handling,data:loading,integration:Databento,library:pandas
CODE:
```
# Export to pandas DataFrame
dbn_data.to_df()
```
----------------------------------------
TITLE: Export DBN Data to CSV File (Python)
DESCRIPTION: Illustrates how to convert and save DBN data into a standard CSV file format using the `dbn_data.to_csv()` method. This is useful for interoperability with spreadsheet software and other data analysis tools.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: CSV,DBN,data format,data:export,data:persistence,integration:Databento
CODE:
```
dbn_data = client.timeseries.get_range(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],
    schema="ohlcv-1h",
    start="2022-06-06",
    limit=3
)

# Export to CSV file
dbn_data.to_csv("GLBX-ESM2-20220606-ohlcv-1h.csv")
```
----------------------------------------
TITLE: Clean, Transform, and Localize Downloaded Data to DataFrame
DESCRIPTION: This comprehensive snippet cleans and transforms the downloaded market data into a pandas DataFrame. It renames columns, drops irrelevant ones, reorders columns for better readability, converts the `ts_event` column to a localized datetime (Bratislava timezone), and adjusts the datetime to represent the bar's closing time. Finally, it prints the DataFrame length and displays the first three rows for preview.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: data handling,data:wrangling,datetime,library:pandas,library:pytz,localization,timezone
CODE:
```
df = (
    data.to_df()
    .reset_index()
    .rename(columns={"ts_event": "datetime"})
    .drop(columns=["rtype", "publisher_id", "instrument_id"])

    # Nice order of columns
    .reindex(columns=["symbol", "datetime", "open", "high", "low", "close", "volume"])

    # Localize datetime to Bratislava
    .assign(datetime = lambda df: pd.to_datetime(df["datetime"], utc=True))  # Mark as UTC datetime
    .assign(datetime = lambda df: df["datetime"].dt.tz_convert(pytz.timezone("Europe/Bratislava")))  # Convert to Bratislava timezone

    # Add 1-minute, so datetime represents closing time of the bar (not opening time)
    .assign(datetime = lambda df: df["datetime"] + timedelta(minutes=1))
)

# Preview
print(len(df))
df.head(3)
```
----------------------------------------
TITLE: Convert DBN Data to NumPy N-dimensional Array (Python)
DESCRIPTION: Explains how to convert DBN data into a NumPy N-dimensional array using `dbn_data.to_ndarray()`. Each element in the array will be a Python tuple representing the binary fields, suitable for numerical computations and scientific applications.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,data format,data handling,integration:Databento,library:numpy
CODE:
```
# Export to numpy-array
ndarray = dbn_data.to_ndarray()
ndarray
```
----------------------------------------
TITLE: Define Data Download Settings
DESCRIPTION: This snippet defines configuration variables for data downloading, including the dataset name, symbol, input stream type (continuous), data schema (1-minute OHLCV), and the start and end dates for the data range. These settings are used in subsequent data fetching operations.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,configuration,data handling,dataset,schema,symbol,time range
CODE:
```
dataset="GLBX.MDP3"
symbol="6E.v.0"
stype_in="continuous"
schema="ohlcv-1m"
start="2025-01-01"
end="2025-01-05"
```
----------------------------------------
TITLE: Discover Databento Dataset Time Range
DESCRIPTION: Identify the earliest and latest available timestamps for a specified Databento dataset. The `start` and `end` values returned by this method are crucial for defining time boundaries when making subsequent requests to `timeseries.get_range` or `batch.submit_job` endpoints.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,dataset range,integration,metadata,time range
CODE:
```
available_range = client.metadata.get_dataset_range(dataset="GLBX.MDP3")
available_range
```
----------------------------------------
TITLE: Load DBN Data Directly from File using DBNStore.from_file (Python)
DESCRIPTION: Provides a streamlined approach to load DBN data directly from a specified file path using the `db.DBNStore.from_file()` method, simplifying access to previously saved DBN data for conversion to a DataFrame.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,DBNStore,data format,data handling,data:loading,from_file,integration:Databento
CODE:
```
loaded_dbn_data = db.DBNStore.from_file(path)
loaded_dbn_data.to_df()
```
----------------------------------------
TITLE: Stream Historical Time Series Data from Databento
DESCRIPTION: Initiate a streaming request to retrieve historical market data, instrument definitions, or status data directly into your application. This method blocks until all requested data is downloaded. The `ts_event` timestamp in the output represents the opening time for aggregated bars.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,data handling,data streaming,data type:historical,integration:Databento
CODE:
```
data = client.timeseries.get_range(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],            # ES (S&P contract) expiring in June 2022
    schema="ohlcv-1h",           # Hourly bars
    start="2022-06-01T00:00:00",
    end="2022-06-03T00:10:00",
    limit=5                    # Optional limit on count of results
)

# Data are received in DBNStore format
data
```
----------------------------------------
TITLE: Load DBN Data from Byte Stream using DBNStore.from_bytes (Python)
DESCRIPTION: Demonstrates how to load DBN data from a raw byte stream, typically obtained by reading a `.dbn.zst` file in binary mode. The `db.DBNStore.from_bytes()` method reconstructs the DBN object, which can then be converted to a pandas DataFrame.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,DBNStore,bytes,data format,data handling,data:loading,from_bytes,integration:Databento
CODE:
```
with open(path, "rb") as saved:
    loaded_dbn_data = db.DBNStore.from_bytes(saved)

loaded_dbn_data.to_df()
```
----------------------------------------
TITLE: Calculate Databento Data Retrieval Costs
DESCRIPTION: Estimate the cost in US dollars for a data retrieval operation from Databento. The calculation is based on the specified dataset, symbols, schema, and the inclusive start and exclusive end timestamps.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: API,Databento,cost estimation,integration,metadata
CODE:
```
cost = client.metadata.get_cost(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],
    schema="ohlcv-1h",  # 1 hour bars ; only time-ranges that are multiplies of 10-minutes (cannot be used for 1-min bars)
    start="2022-01-06", # including start
    end="2022-01-07"    # excluding end
)

cost
```
----------------------------------------
TITLE: Export DBN Data to Zstandard Compressed DBN File (Python)
DESCRIPTION: Provides a direct example of saving DBN data to a Zstandard compressed DBN file using the `dbn_data.to_file()` method. This is the primary method for persisting DBN objects in their native format.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,ZST,compression,data format,data:export,data:persistence,integration:Databento
CODE:
```
# Export to DBN file
dbn_data.to_file("GLBX-ESM2-20220606.ohlcv-1h.dbn.zst")
```
----------------------------------------
TITLE: Convert Databento DBNStore to Pandas DataFrame
DESCRIPTION: Transform the proprietary DBNStore format, received from Databento, into a more widely usable pandas DataFrame. This conversion facilitates data analysis and manipulation within Python. The `rtype` field in the DataFrame indicates the type of bar or record.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,data format,data handling,data:loading,integration:Databento,library:pandas
CODE:
```
# Convert DBN format to pandas-dataframe
df = data.to_df()

# Preview
print(len(df))
df
```
----------------------------------------
TITLE: List Supported Databento Schemas
DESCRIPTION: Retrieve a list of all supported data formats (schemas) available within a specified Databento dataset. This helps identify the types of market data and other information that can be queried.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,documentation:API-reference,integration,list_schemas,metadata,schemas
CODE:
```
schemas = client.metadata.list_schemas(dataset="GLBX.MDP3")
schemas
```
----------------------------------------
TITLE: Export DBN Data to Apache Parquet File (Python)
DESCRIPTION: Shows how to write DBN data to an Apache Parquet file using the `dbn_data.to_parquet()` method. Parquet is a columnar storage format optimized for analytical queries and efficient data processing.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,Parquet,data format,data:export,data:persistence,integration:Databento
CODE:
```
# Export to Apache Parquet file
dbn_data.to_parquet("GLBX-ESM2-20220606-ohlcv-1h.parquet")
```
----------------------------------------
TITLE: Save DBN Data to Zstandard Compressed File (Python)
DESCRIPTION: Shows how to persist DBN data to a file using the `dbn_data.to_file()` method. The recommended file suffix is `.dbn.zst` for Zstandard compression, ensuring efficient storage of time series data.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,ZST,compression,data format,data:persistence,integration:Databento
CODE:
```
path = "./GLBX-ESM2-20220606.ohlcv-1h.dbn.zst"
dbn_data.to_file(path)
```
----------------------------------------
TITLE: Check Databento Dataset Availability and Quality
DESCRIPTION: Query the Databento API to determine the availability and quality status of a specific dataset over a given date range. The response indicates whether data is 'available' for each day and when it was last modified.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: API,Databento,data quality,dataset condition,integration,metadata
CODE:
```
conditions = client.metadata.get_dataset_condition(
    dataset="GLBX.MDP3",
    start_date="2022-06-06",
    end_date="2022-06-10",
)

conditions
```
----------------------------------------
TITLE: Export DBN Data to JSON File (Python)
DESCRIPTION: Demonstrates how to save DBN data into a JSON file format using the `dbn_data.to_json()` method. This is suitable for web-based applications or data exchange where JSON is the preferred format.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,JSON,data format,data:export,data:persistence,integration:Databento
CODE:
```
# Export to pandas DataFrame
dbn_data.to_json("GLBX-ESM2-20220606-ohlcv-1h.json")
```
----------------------------------------
TITLE: Check Data Download Cost
DESCRIPTION: This snippet demonstrates how to estimate the cost of downloading a specific range of market data using `client.metadata.get_cost`. It takes the same parameters as the data download function to calculate the approximate cost in dollars before proceeding with the actual download.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: API,Databento,cost estimation,integration,metadata
CODE:
```
cost = client.metadata.get_cost(
    dataset=dataset,
    symbols=[symbol],
    stype_in=stype_in,
    schema=schema,
    start=start,
    end=end,
)

print(f"{cost:.2f}$")
```
----------------------------------------
TITLE: Load OHLCV Data for a Specific Range
DESCRIPTION: This snippet demonstrates how to fetch historical OHLCV (Open, High, Low, Close, Volume) data for a given symbol and time range using the `client.timeseries.get_range` method. It specifies the dataset, symbols, schema, start date, and a limit for the number of bars. The fetched data is then converted to a pandas DataFrame for easy viewing.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,OHLCV,bar,data handling,data:loading,integration,time range
CODE:
```
dbn_data = client.timeseries.get_range(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],
    schema="ohlcv-1h",
    start="2022-06-06",
    limit=3
)

dbn_data.to_df()
```
----------------------------------------
TITLE: Iterate and Print Full Bar Data from DBN
DESCRIPTION: This example shows how to iterate through the loaded DBN data. Each iteration yields a full bar object. The `break` statement is used to display only the first bar's complete data structure, illustrating the format of individual OHLCV messages.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,bar,data format,data handling,inspection,integration:Databento,iteration
CODE:
```
for bar in dbn_data:
    print(bar)   # print full bar data
    break        # intentionally break to see only 1st bar
```
----------------------------------------
TITLE: Access Specific Fields During DBN Data Iteration
DESCRIPTION: This snippet demonstrates how to access specific attributes of a bar object (e.g., `bar.open`) while iterating through the DBN data. It prints only the 'open' price for the first bar, showing how to extract individual data points from the structured bar objects.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: DBN,bar,data format,data handling,field access,inspection,integration:Databento,iteration
CODE:
```
for bar in dbn_data:
    print(f"Bar open: {bar.open}")  # print only bar-open information
    break                           # intentionally break to see only 1st bar
```
----------------------------------------
TITLE: Supported Symbology Input/Output Combinations
DESCRIPTION: Illustrates the supported combinations of input and output symbology types when requesting data from various exchanges and publishers.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: APIDOC
KEYWORDS: Databento,documentation:API-reference,instrument ID,integration,mapping,raw_symbol,symbology
CODE:
```
SType in | SType out | DBEQ.BASIC | GLBX.MDP3 | IFEU.IMPACT | NDEX.IMPACT | OPRA.PILLAR | XNAS.ITCH
parent | instrument_id | | ✓ | ✓ | ✓ | ✓ |
continuous | instrument_id | | ✓ | | | |
raw_symbol | instrument_id | ✓ | ✓ | ✓ | ✓ | ✓ | ✓
instrument_id | raw_symbol | ✓ | ✓ | ✓ | ✓ | ✓ | ✓
```
----------------------------------------
TITLE: List Databento Datasets
DESCRIPTION: Fetches a list of all available datasets from the Databento Historical API metadata endpoint. Each dataset is formatted as `PUBLISHER.DATASET`.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,datasets,integration,list_datasets,metadata
CODE:
```
datasets = client.metadata.list_datasets()
datasets
```
----------------------------------------
TITLE: Authenticate and Connect to Databento Historical API
DESCRIPTION: Demonstrates how to establish a connection and authenticate with the Databento Historical API using a provided API key.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: API client,authentication,data type:historical,integration:Databento
CODE:
```
import databento as db


# Establish connection and authenticate
API_KEY = "db-8VWGBis54s4ewGVciMRakNxLCJKen"   # put your API key here (existing key is just example, not real)
client = db.Historical(API_KEY)
```
----------------------------------------
TITLE: List Databento Data Publishers
DESCRIPTION: Retrieves a list of all available data publishers from the Databento Historical API metadata endpoint. The example shows how to display the first five entries.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: Databento,integration,list_publishers,metadata,publishers
CODE:
```
publishers = client.metadata.list_publishers()

# Show only first five from long list
publishers[:5]
```
----------------------------------------
TITLE: Get Record Count for Databento Data Query
DESCRIPTION: Obtain the total number of records that would be returned by a data query, based on the specified dataset, symbols, schema, and time range. The `end` parameter for the time range is exclusive.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: API,Databento,get_record_count,integration,metadata,record count
CODE:
```
record_count = client.metadata.get_record_count(
    dataset="GLBX.MDP3",
    symbols=["ESM2"],   # ES (S&P contract) expiring in June 2022
    schema="ohlcv-1h",  # 1 hour bars ; only time-ranges that are multiplies of 10-minutes (cannot be used for 1-min bars)
    start="2022-01-06", # including start
    end="2022-01-07"    # excluding end
)

# There is one hour break on the exchange, so 23 hourly bars are OK
record_count
```
----------------------------------------
TITLE: Databento Symbology Types
DESCRIPTION: Describes the five symbology types used by Databento for naming instruments, including their descriptions, examples, and key notes. Abbreviation `stypes` is often used in API and docs and means "symbology types".
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: APIDOC
KEYWORDS: Databento,continuous,documentation:API-reference,instrument ID,integration,parent,raw_symbol,symbology
CODE:
```
Symbology Type | Description | Example/Pattern | Key Notes
raw_symbol | Original string symbols used by data publisher | AAPL, ESH3 | Best for direct market connectivity environments
instrument_id | Unique numeric IDs assigned by publisher | 12345, 9876543 | Space-efficient but can be remapped daily by some publishers
parent | Groups related symbols using root symbol | ES.FUT, ES.OPT | Allows querying all futures/options for a root symbol at once
continuous | References instruments that change over time | ES.c.0, CL.n.1, ZN.v.0 | Roll rules: Calendar (c), Open Interest (n), Volume (v)
ALL_SYMBOLS | Requests all symbols in dataset | ALL_SYMBOLS |
```
----------------------------------------
TITLE: Databento Data Schemas Reference
DESCRIPTION: Detailed reference for various Databento data schemas, including their type, description, and granularity levels (L3, L2, L1). These schemas define the structure and content of market data available from Databento.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: APIDOC
KEYWORDS: Databento,MBO,MBP,OHLCV,data type:market-data,definition,documentation:API-reference,integration,schemas,trades
CODE:
```
Schema: mbo
  Type: L3 data
  Description: Provides every order book event across every price level, keyed by order ID. Allows determination of queue position for each order, offering highest level of granularity available.
Schema: mbp-10
  Type: L2 data
  Description: Provides every order book event across top ten price levels, keyed by price. Includes trades and changes to aggregate market depth, with total size and order count at top ten price levels.
Schema: mbp-1
  Type: L1 data
  Description: Provides every order book event updating the top price level (BBO). Includes trades and changes to book depth, with total size and order count at BBO.
Schema: bbo-1s
  Type: L1 sampled
  Description: Similar to L1 data but sampled in 1 second intervals. Provides last best bid, best offer, and sale at 1-second intervals.
Schema: tbbo
  Type: L1 trades
  Description: Provides every trade event alongside the BBO immediately before the effect of each trade. Subset of MBP-1.
Schema: trades
  Type: Trade data
  Description: Provides every trade event. This is a subset of MBO data.
Schema: ohlcv-1s
  Type: 1s bars
  Description: OHLCV bars aggregated from trades at 1-second intervals.
Schema: ohlcv-1m
  Type: 1m bars
  Description: OHLCV bars aggregated from trades at 1-minute intervals.
Schema: ohlcv-1h
  Type: 1h bars
  Description: OHLCV bars aggregated from trades at 1-hour intervals.
Schema: ohlcv-1d
  Type: 1d bars
  Description: OHLCV bars aggregated from trades at 1-day intervals.
Schema: definition
  Type: Reference
  Description: Provides reference information about instruments including symbol, name, expiration date, listing date, tick size, strike price.
Schema: status
  Type: Exchange status
  Description: Provides updates about trading session like halts, pauses, short-selling restrictions, auction start, and other matching engine statuses.
Schema: statistics
  Type: Exchange stats
  Description: Provides official summary statistics published by venue, including daily volume, open interest, settlement prices, and official open/high/low prices.
```
----------------------------------------
TITLE: Import Libraries and Configure Pandas Display Options
DESCRIPTION: This snippet imports necessary libraries: `timedelta` for time calculations, `pandas` for data manipulation, and `pytz` for timezone handling. It also configures pandas display options to show all columns and rows, which is useful for inspecting large DataFrames.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: python
KEYWORDS: configuration,dev:imports,development,display options,library:pandas,library:pytz
CODE:
```
from datetime import timedelta

import pandas as pd
import pytz


pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", None)
```
----------------------------------------
TITLE: Install Databento Python Library
DESCRIPTION: Instructions to install the Databento Python client library using pip, enabling access to Databento's market data services.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: Python
KEYWORDS: API client,dev:installation,development,integration:Databento
CODE:
```
pip install -U databento
```
----------------------------------------
TITLE: Databento Binary Encoding (DBN) File Format
DESCRIPTION: Explains Databento's proprietary DBN file format, highlighting its performance and compression benefits over CSV/JSON for market data.
SOURCE: docs/tutorials/databento_overview.ipynb
LANGUAGE: APIDOC
KEYWORDS: DBN,Databento,compression,documentation:API-reference,file format,integration,performance
CODE:
```
Databento uses its own file format for market-data. It is called Databento Binary Encoding (DBN).
Think of it like more performant + compressed alternative of CSV / JSON files.
You can easily load DBN file and convert it into simple CSV / JSON data.
```